{"course code":"ECPE81","course title":"Pattern recognition and machinenlearning","number of credits":"03","prerequisites":"ECPC32","course type":"PE","branch":"ec","course learning objectives":"The student should be able to understand and apply the various concepts of Pattern recognition and machine learning.","course content":"## UNIT InnIntroductionnPolynomial Curve Fitting, Probability Theory Model Selection, The Curse of Dimensionality, Decision Theory, Information Theory,Probability Distributions,Binary Variables, Multinomial Variables, The Gaussian Distribution ,The Exponential Family, Nonparametric Methods,Linear Models for Regression, Linear Basis Function Models, The Bias-Variance Decomposition, Bayesian Linear Regression, Bayesian Model Comparison, The Evidence Approximation, Limitations of Fixed Basis Functions, Linear Models for Classification, Discriminant Functions, Probabilistic Generative Models, Probabilistic Discriminative Models The Laplace Approximation, Bayesian Logistic Regression.nnn## UNIT IInnFeed-forward Network FunctionsnNetwork Training, Error Backpropagation, The Hessian Matrix, Regularization in Neural Networks, Mixture Density Networks, Bayesian Neural Networks Dual Representations, Constructing Kernels, Radial Basis Function Networks, Gaussian Processes,Sparse Kernel Machines, Maximum Margin Classifiers, Relevance Vector Machines.nnn## UNIT IIInnGraphical ModelsnBayesian Networks, Conditional Independence, Markov Random Fields, Inference in Graphical Models, Mixture Models and EM, K-means Clustering, Mixtures of Gaussians, An Alternative View of EM, The EM Algorithm in General, Approximate Inference, Variational Inference,nVariational Mixture of Gaussians, Variational Linear Regression, Exponential Family Distributions, Local Variational Methods, Variational Logistic Regression, Expectation Propagation,Sampling Methods, Basic Sampling Algorithms, Markov Chain Monte Carlo, Gibbs Sampling, Slice Sampling, The Hybrid Monte Carlo Algorithm, Estimating the Partition Function.nnn## UNIT IVnnContinuous Latent VariablesnPrincipal Component Analysis, Probabilistic PCA, Kernel PCA, Nonlinear Latent Variable Models, Sequential Data , Markov Models, Hidden Markov Models, Linear Dynamical Systems, Combining Models, Bayesian Model Averaging, Committees, Boosting, Tree-based Models, Conditional Mixture Models.","reference books":"- C. M. Bishop, Pattern Recognition and machine learning, springer, 2006.n- Tom M. Mitchell, Machine Learning, Mc Graw-Hill, 1997.","course outcomes":"At the end of the course student will be able to:n- Develop the understanding about fundamentals of pattern recognition and machine learning.n- Apply supervised and unsupervised learning techniques.n- Understand and apply SVM.n- Understand different graphical models.n- Understand different clustering techniques.n- Apply continuous latent variable and its mixture models."}
